{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model from auvlib data\n",
    "\n",
    "Let's start by importing some useful functions. In this tutorial we are going to use [pytorch](https://pytorch.org/) for training a neural network. Let's import the necessary modules..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from data.aligned_dataset import AlignedDataset\n",
    "from util import visualizer as vs\n",
    "from util import net_util\n",
    "import os\n",
    "import functools\n",
    "from util import html\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the neural network\n",
    "\n",
    "We are going to train a convolutional network with residual blocks, a so called [*resnet*](https://arxiv.org/abs/1512.03385), to map sidescan patches to corresponding sea floor depths. A resnet is a popular for of neural network that uses skip connections to facilitate training, see sketch below. To begin with, let us define the network structure. ![resnet](ResNets.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetBlock(nn.Module):\n",
    "    \"\"\"Define a Resnet block\"\"\"\n",
    "\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Initialize the Resnet block\n",
    "\n",
    "        A resnet block is a conv block with skip connections\n",
    "        We construct a conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> function.\n",
    "        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"Construct a convolutional block.\n",
    "\n",
    "        Parameters:\n",
    "            dim (int)           -- the number of channels in the conv layer.\n",
    "            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers.\n",
    "            use_bias (bool)     -- if the conv layer uses bias or not\n",
    "\n",
    "        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n",
    "        \"\"\"\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward function (with skip connections)\"\"\"\n",
    "        out = x + self.conv_block(x)  # add skip connections\n",
    "        return out\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"Resnet-based generator that consists of Resnet blocks between a few downsampling/upsampling operations.\n",
    "\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project(https://github.com/jcjohnson/fast-neural-style)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
    "        \"\"\"Construct a Resnet-based generator\n",
    "\n",
    "        Parameters:\n",
    "            input_nc (int)      -- the number of channels in input images\n",
    "            output_nc (int)     -- the number of channels in output images\n",
    "            ngf (int)           -- the number of filters in the last conv layer\n",
    "            norm_layer          -- normalization layer\n",
    "            use_dropout (bool)  -- if use dropout layers\n",
    "            n_blocks (int)      -- the number of ResNet blocks\n",
    "            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n",
    "        \"\"\"\n",
    "        assert(n_blocks >= 0)\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 2\n",
    "        for i in range(n_downsampling):  # add downsampling layers\n",
    "            mult = 2 ** i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2 ** n_downsampling\n",
    "        for i in range(n_blocks):       # add ResNet blocks\n",
    "\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "        for i in range(n_downsampling):  # add upsampling layers\n",
    "            mult = 2 ** (n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "                                         kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1,\n",
    "                                         bias=use_bias),\n",
    "                      norm_layer(int(ngf * mult / 2)),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.ReflectionPad2d(3)]\n",
    "        model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "        model += [nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward\"\"\"\n",
    "        return self.model(input)\n",
    "    \n",
    "def save_network(save_dir, epoch):\n",
    "    \"\"\"Save the network to the disk.\n",
    "    Parameters:\n",
    "        epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "    \"\"\"\n",
    "    save_filename = '%s_resnet.pth' % (epoch,)\n",
    "    save_path = os.path.join(save_dir, save_filename)\n",
    "\n",
    "    torch.save(net.state_dict(), save_path)\n",
    "    \n",
    "def load_network(save_dir, epoch, device):\n",
    "    \"\"\"Load the network from disk.\n",
    "    Parameters:\n",
    "        epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
    "        device (str) -- the name of the torch device (e.g. \"cpu\")\n",
    "    \"\"\"\n",
    "    save_filename = '%s_resnet.pth' % (epoch,)\n",
    "    save_path = os.path.join(save_dir, save_filename)\n",
    "    \n",
    "    norm_layer = net_util.get_norm_layer(norm_type='batch')\n",
    "    model = ResnetGenerator(1, 1, 64, norm_layer=norm_layer, use_dropout=True, n_blocks=6).to(device)\n",
    "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training\n",
    "\n",
    "The network will get loaded on the GPU if there is one available. Note that training requires a GPU, while testing could be done on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n"
     ]
    }
   ],
   "source": [
    "norm_layer = net_util.get_norm_layer(norm_type='batch')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ResnetGenerator(1, 1, 64, norm_layer=norm_layer, use_dropout=True, n_blocks=6).to(device)\n",
    "net_util.init_weights(net, init_type='normal', init_gain=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a L1 loss to force the predicted depths to be close to the ground truth depths of the training examples. We will use the Adam optmizer because we found that it works good while being fast. However, one could also use the standard stochastic gradient descent method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to feed in the images that we stored in the previous part of the tutorial. For the training part, we will use the images from the `train` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = 'sss2depth' # the name of the dataset folder\n",
    "batch_size = 1 # number of examples to feed in at a time\n",
    "epochs = 100 # number of epochs to train the network\n",
    "\n",
    "opt = net_util.get_default_train_options() # e.g. display config\n",
    "opt.batch_size = batch_size\n",
    "opt.dataroot = dataroot\n",
    "opt.phase = 'train'\n",
    "# this iterator will feed data to our network\n",
    "dataset = torch.utils.data.DataLoader(\n",
    "                AlignedDataset(opt),\n",
    "                batch_size=opt.batch_size,\n",
    "                shuffle=not opt.serial_batches,\n",
    "                num_workers=int(opt.num_threads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Now we are ready to start training our network. Every 5 epochs we will save the current model in `checkpoints/XX_resnet.pth`. You can inspect the process of the training in [visdom](http://localhost:8097/). The website should look something like this: ![visdom](visdom.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a visualizer that display/save images and plots\n",
    "visualizer = vs.Visualizer(opt)\n",
    "\n",
    "# show a colorbar between the min and max depths as defined before\n",
    "visualizer.display_colorbar_jet(-19., -11.)\n",
    "\n",
    "dataset_size = len(dataset) # the number of examples in dataset\n",
    "display_freq = 100 # how often to update web page images\n",
    "update_html_freq = 1000 # how often to save html on disk\n",
    "\n",
    "total_iters = 0\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataset):\n",
    "        visualizer.reset()\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data['A'].to(device)\n",
    "        target = data['B'].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mask = (target > -.99).float()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(mask*outputs, mask*target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % display_freq == 0: # display images on visdom and save images to a HTML file\n",
    "            save_result = i % update_html_freq == 0\n",
    "            visual_ret = {'Input': inputs, 'Output_Jet': mask*(outputs+1.)-1., 'Real_Jet': target}\n",
    "            visualizer.display_current_results(visual_ret, epoch, save_result)\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        total_iters += 1\n",
    "        if total_iters % 20 == 0: # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20.))\n",
    "            print('Epoch %d / %d, example %d / %d' % (epoch + 1, epochs, i+1, dataset_size))\n",
    "            losses = {'L1_loss': running_loss/20.}\n",
    "            print float(i)/dataset_size\n",
    "            visualizer.plot_current_losses(epoch, float(i) / dataset_size, losses)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    if epoch % 5 == 0: # cache our model every 5 epochs\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, i))\n",
    "        save_network('checkpoints', 'latest')\n",
    "        save_network('checkpoints', epoch)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the network\n",
    "\n",
    "We can now load any of the saved epochs and test the trained model on our test dataset. The results will be stored in `results/regress/test_XX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.phase = \"test\"\n",
    "opt.isTrain = False\n",
    "opt.dataroot = \"sss2depth\"\n",
    "epoch = \"latest\"\n",
    "\n",
    "dataset = torch.utils.data.DataLoader(\n",
    "                AlignedDataset(opt),\n",
    "                batch_size=opt.batch_size,\n",
    "                shuffle=not opt.serial_batches,\n",
    "                num_workers=int(opt.num_threads))\n",
    "\n",
    "net = load_network('checkpoints', epoch, device)      # create a model given opt.model and other options\n",
    "\n",
    "# create a website\n",
    "web_dir = os.path.join(\"results\", opt.name, '%s_%s' % (\"test\", epoch))  # define the website directory\n",
    "webpage = html.HTML(web_dir, 'Experiment = %s, Phase = %s, Epoch = %s' % (opt.name, opt.phase, epoch))\n",
    "\n",
    "num_test = 25\n",
    "for i, data in enumerate(dataset):\n",
    "    if i >= num_test:  # only apply our model to opt.num_test images.\n",
    "        break\n",
    "    inputs = data['A'].to(device)\n",
    "    target = data['B'].to(device)\n",
    "    \n",
    "    mask = (target > -.99).float()\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    visuals = {'Input': inputs, 'Output_Jet': mask*(outputs+1.)-1., 'Real_Jet': target}\n",
    "    img_path = data['A_paths'] # get image paths\n",
    "    if i % 5 == 0:  # save images to an HTML file\n",
    "        print('processing (%04d)-th image... %s' % (i, img_path))\n",
    "    vs.save_images(webpage, visuals, img_path, aspect_ratio=opt.aspect_ratio, width=opt.display_winsize)\n",
    "webpage.save()  # save the HTML\n",
    "\n",
    "# show the saved web page with results\n",
    "IFrame(src=os.path.join(web_dir, \"index.html\"), width=850, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
